{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa47034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras\n",
    "#pip install tensorflow\n",
    "#pip install matplotlib\n",
    "#pip install sklearn\n",
    "#pip install numpy\n",
    "#pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6a3d02",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset we will work with today is a famous AI starter dataset called the MNIST database of handwritten digits. More documentation can be found here: http://yann.lecun.com/exdb/mnist/. It is important to know what you are working with, so I highly recommend reading over the documentation and learning a few things about your data format and meaning.\n",
    "\n",
    "First, we will want to load the data, then we will explore it and try to train some classifiers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16252c7",
   "metadata": {},
   "source": [
    "The code below will load the dataset in from the existing keras python library. There are a few different datasets here that can be used by the public like image classifications, movie reviews and Boston housing prices. Keras does some work for us here in separating our data into training and test sets like we talked about in the lecture. \n",
    "\n",
    "If we did not want to use keras, we could also use sklearn's train_test_split function (documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)) or write a method by ourselves!\n",
    "\n",
    "For today, we will just use the pre-existing functionality but feel free to try other alternatives if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35faf5d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X /= 255\n",
    "test_X /= 255\n",
    "train_y = tf.keras.utils.to_categorical(train_y, 10)\n",
    "test_y = tf.keras.utils.to_categorical(test_y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc420c6",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "One of the toughest parts with Artificial Intelligence is learning your data and making it as useful as possible. There is a whole industry centered around this called Data Science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6e8854",
   "metadata": {},
   "source": [
    "This code below should get you started on analyzing the data. We first want to visualize it and see the pixels, but we also want to know how the data is being stored. Dig deeper into the actual contents now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff22b375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "_, axs = pyplot.subplots(3, 3, figsize=(5, 5))\n",
    "pyplot.subplots_adjust(hspace=0.5)\n",
    "axs = axs.flatten()\n",
    "for i, ax in zip(range(9), axs):\n",
    "    ax.imshow(train_X[i], cmap=pyplot.get_cmap('gray'))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f86d3a",
   "metadata": {},
   "source": [
    "Play around with the data a bit... here are some questions you should look to answer:\n",
    "- What sizes are each dataset?\n",
    "- How many of each value is in the label datasets?\n",
    "- Does the test set accurately represent the training set? Are the percentages of each label the same?\n",
    "- Is the data in order based on number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8483cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b35642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counds in each label dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba3a16a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test and train similar world representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset ordered or unordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23241e9a",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "Now that we know a little more information about the data we are trying to use, lets start working on a neural network that given the pixel information, will be able to tell us what handwritten number it is.\n",
    "\n",
    "We are going to create a Multi-layer Perceptron Classifier! Read [this](https://www.tensorflow.org/api_docs/python/tf/keras/Model) over and get a general idea of the methods we are going to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d4365f",
   "metadata": {},
   "source": [
    "Below is an implementation of a sequential model with layers in it. If you are to run the rest of this section, you can see that the model does not do a good job on classifying the numbers. I want you to add more layers, move things around, change loss functions or optimizers to get a better working model. Feel free to ask any questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(28, 28, 1)\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=input_shape),\n",
    "        tf.keras.layers.Conv2D(10, kernel_size=(10, 10), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(7, 7)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9fc6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_X, y=train_y, epochs=10, batch_size=300, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe9e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_X, test_y, verbose=0)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5194ec53",
   "metadata": {},
   "source": [
    "## Metrics Visualization\n",
    "\n",
    "We might want to see certain metrics as time goes on in our training. One of the most used graphs is a correlation matrix which we will display here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "prediction = model.predict(test_X)\n",
    "prediction = prediction.argmax(axis=1)\n",
    "conf = confusion_matrix(prediction, test_y.argmax(axis=1))\n",
    "\n",
    "ax= pyplot.subplot()\n",
    "sns.heatmap(conf, annot=True, fmt='g', ax=ax)\n",
    "\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
